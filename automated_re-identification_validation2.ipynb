{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812255a-02f6-475f-9a6b-abb1cc4d8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from cryptography.fernet import Fernet\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "json_folder = \"C:/Users/User/Desktop/UltraSafeReview/deidentification_reidentification/reidentified_valid_images11\"\n",
    "xml_folder = \"C:/Users/User/Desktop/UltraSafeReview/image_validity/xml_files11\"\n",
    "output_file = \"C:/Users/User/Desktop/UltraSafeReview/metadata_summary.json\"\n",
    "\n",
    "# Encryption key for decryption\n",
    "encryption_key = b'rv9QPS5m7IThOFMLUmJcECJ_5izPGPh2CxI7LJUuOGI='\n",
    "handle_encryption = Fernet(encryption_key)\n",
    "\n",
    "# Function to decrypt and read JSON metadata\n",
    "def decrypt_json_file(json_path):\n",
    "    try:\n",
    "        with open(json_path, 'rb') as file:\n",
    "            encrypted_data = file.read()\n",
    "        decrypted_data = handle_encryption.decrypt(encrypted_data)\n",
    "        metadata = json.loads(decrypted_data.decode('utf-8'))\n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: Failed to decrypt or parse JSON file '{json_path}': {e}\"\n",
    "\n",
    "# Function to process all JSON files and save results to a single JSON file\n",
    "def process_json_files(json_folder):\n",
    "    metadata_summary = {}\n",
    "    for file_name in os.listdir(json_folder):\n",
    "        if file_name.endswith('.json'):\n",
    "            json_file_path = os.path.join(json_folder, file_name)\n",
    "            base_name = file_name.replace('.json', '')\n",
    "            print(f\"Processing '{file_name}'...\")\n",
    "            metadata = decrypt_json_file(json_file_path)\n",
    "            if isinstance(metadata, str) and metadata.startswith(\"ERROR\"):\n",
    "                print(metadata)\n",
    "            else:\n",
    "                # Extract only the text fields from metadata\n",
    "                text_only_metadata = [item['text'].strip().lower() for item in metadata if 'text' in item]\n",
    "                metadata_summary[base_name] = text_only_metadata\n",
    "\n",
    "    # Save the summary to a JSON file\n",
    "    with open(output_file, 'w') as output:\n",
    "        json.dump(metadata_summary, output, indent=4)\n",
    "    print(f\"Metadata summary saved to '{output_file}'\")\n",
    "    return metadata_summary\n",
    "\n",
    "# Function to parse XML files and extract relevant data\n",
    "def parse_xml_files(xml_folder):\n",
    "    xml_data = {}\n",
    "    for file_name in os.listdir(xml_folder):\n",
    "        if file_name.endswith('.xml'):\n",
    "            file_path = os.path.join(xml_folder, file_name)\n",
    "            tree = ET.parse(file_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Extract the filename without extension\n",
    "            file_names_in_xml = [elem.text.replace('.tif', '').strip() for elem in root.findall(\".//FileName\") if elem.text.endswith('.tif')]\n",
    "\n",
    "            # Extract PHI fields\n",
    "            file_data = {\n",
    "                \"InstitutionName\": root.findtext(\".//InstitutionName\", \"\").strip().lower(),\n",
    "                \"FamilyName\": root.findtext(\".//FamilyName\", \"\").strip().lower(),\n",
    "                \"GivenName\": root.findtext(\".//GivenName\", \"\").strip().lower(),\n",
    "                \"Sex\": root.findtext(\".//Sex\", \"\").strip().lower(),\n",
    "                \"DicomPatientID\": root.findtext(\".//DicomPatientID\", \"\").strip().lower(),\n",
    "                \"DicomProtocolName\": root.findtext(\".//DicomProtocolName\", \"\").strip().lower()\n",
    "            }\n",
    "\n",
    "            for fname in file_names_in_xml:\n",
    "                xml_data[fname] = file_data\n",
    "\n",
    "    return xml_data\n",
    "\n",
    "# Function to clean text by removing punctuation\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9]', '', text).lower()\n",
    "\n",
    "# Function to validate if the DicomPatientID is an approximate match\n",
    "def is_approximate_match(field_value, metadata_text):\n",
    "    # Clean the field value and look for approximate matches in the metadata\n",
    "    cleaned_field = clean_text(field_value)\n",
    "    for text in metadata_text:\n",
    "        if cleaned_field in text or text in cleaned_field:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to validate re-identification by comparing XML and JSON data\n",
    "def validate_reidentification(metadata_summary, xml_data):\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    failed_files = []\n",
    "\n",
    "    for file_name, metadata_text in metadata_summary.items():\n",
    "        if file_name in xml_data:\n",
    "            xml_fields = xml_data[file_name]\n",
    "            missing_fields = []\n",
    "\n",
    "            # Clean metadata text\n",
    "            cleaned_metadata = [clean_text(text) for text in metadata_text]\n",
    "\n",
    "            for field, value in xml_fields.items():\n",
    "                if value:\n",
    "                    # Special handling for approximate DicomPatientID match\n",
    "                    if field == \"DicomPatientID\":\n",
    "                        if not is_approximate_match(value, cleaned_metadata):\n",
    "                            missing_fields.append(field)\n",
    "                    else:\n",
    "                        # Clean and split XML field into words\n",
    "                        words = [clean_text(word) for word in value.split()]\n",
    "                        if not all(word in cleaned_metadata for word in words):\n",
    "                            missing_fields.append(field)\n",
    "\n",
    "            if not missing_fields:\n",
    "                success_count += 1\n",
    "            else:\n",
    "                failure_count += 1\n",
    "                failed_files.append((file_name, missing_fields))\n",
    "        else:\n",
    "            failure_count += 1\n",
    "            failed_files.append((file_name, ['No corresponding XML data']))\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Number of successful re-identifications: {success_count}\")\n",
    "    print(f\"Number of failed re-identifications: {failure_count}\")\n",
    "    if failed_files:\n",
    "        print(\"Failed files and missing fields:\")\n",
    "        for failed_file, fields in failed_files:\n",
    "            print(f\"{failed_file}: Missing fields - {fields}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    metadata_summary = process_json_files(json_folder)\n",
    "    xml_data = parse_xml_files(xml_folder)\n",
    "    validate_reidentification(metadata_summary, xml_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
